#!/usr/bin/env python3

from pathlib import Path
import argparse
import datetime
import json
import os
import time
import todoist
import pickle

CONFIG_PATH = str(Path.home()) + "/.todoist_api"
CACHE_PATH = "/tmp/todoist-polybar-cache"
API_KEY=None
with open(CONFIG_PATH, 'r') as content_file:
    API_KEY = content_file.read()

parser = argparse.ArgumentParser(description='Todoist Polybar Widget')
parser.add_argument('--cachettl',
                    '-ttl',
                    type=int,
                    default=5,
                   help='time for cache to be kept in minutes')
parser.add_argument('--update',
                    '-u',
                    action='store_true',
                    default=False,
                    help='when using this flag it will not load previous results from cache, it will however save new results to cache. You can use this flag to refresh all the cache forcefully')


# Setup todoist

# Helper functions
def convert_timestamp(time_str, tz):
    value = None;
    try:
        value = datetime.datetime.strptime(time_str, "%Y-%m-%dT%H:%M:%SZ").astimezone(tz=tz)
    except:
        try:
            value = datetime.datetime.strptime(time_str, "%Y-%m-%dT%H:%M:%S").astimezone(tz=tz)
        except:
            value = datetime.datetime.strptime(time_str, "%Y-%m-%d").astimezone(tz=tz)

    return value

def calculate_date_delta(timestamp, now, tz):
    # Compute difference between the dates
    return convert_timestamp(timestamp, tz).date() - now.date()

def filter_due_items (items):
    # Return only items that have due dates
    return filter(lambda x: x.data['due'] != None and x.data['date_completed'] is None, items)

def filter_due_by_days (api, tz, days):
    now = datetime.datetime.now(tz=tz)
    return filter(lambda x: calculate_date_delta(x.data['due']['date'], now, tz).days <= days, filter_due_items(api.state['items']))

def replace_priority_with_text(priority):
    return {
        '4': 'Important & Urgent',
        '3': 'Important',
        '2': 'Not important but urgent',
        '1': 'Nice to have'
    }[str(priority)]

def save_cache(result):
    with open(CACHE_PATH, 'wb') as f:
        f.write(pickle.dumps(result))

def load_cache(cachettl):

    if not os.path.exists(CACHE_PATH):
        return None

    if time.time() - os.path.getmtime(CACHE_PATH) > cachettl * 60:
        return None

    with open(CACHE_PATH, 'rb') as f:
        try:
            return pickle.loads(f.read());
        except:
            #print("Error while reading cache")
            return None

def main():

    args = parser.parse_args()
    result = None

    if not args.update:
        result = load_cache(args.cachettl)
        #print("Loaded from CACHE: %s" % result)

    if result is None:

        #print("Get result from API")

        api = todoist.TodoistAPI(API_KEY);
        api.sync()

        # Setup timezone
        from dateutil import tz
        tz = tz.gettz(api.state['user']['tz_info']['timezone'])

        result = list(map(
                lambda x: (
                    x.data['content'],
                    convert_timestamp(x.data['due']['date'], tz).date(),
                    x.data['priority'],
                    x.data,
                ),
                list(filter_due_by_days(api, tz, 0))
        ))
        result.sort(key=lambda x: (-x[2], x[1]))

        save_cache(result)

    if result:
        print("%s: %s" % (replace_priority_with_text(result[0][2]), result[0][0]))

if __name__ == '__main__':
    main()
